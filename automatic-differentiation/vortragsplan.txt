* Diagramm (f, f', Code für f, Code für f')
* Plots, die Probleme von ND illustrieren
* Spaßrechnung: (x+eps)^2, (x+eps)^3, 1/(x+eps)
* Etwas genauer: die dualen Zahlen
* Haskell- und Python-Code
* Wieso funktioniert AD? Theorem für Polynome und allgemeines Theorem
* Nähe in C^0-Norm ==/==> Nähe in C^1-Norm
* Krasser Trick: Imag(f(x+ih)/h), siehe [1]
* Ausblick: mehrere Variablen, Rückwärtsmodus (siehe [2], Rückpropagation =
  Rückwärtsmodus der Auswertungsfunktion), SDG

Ein schönes Übersichtsartikel:
Bischof, Bücker. Computing Derivatives of Computer Programs.
https://juser.fz-juelich.de/record/44658/files/Band_3_Winterschule.pdf, S. 315--327.

[1] ttps://adl.stanford.edu/hyperdual/Fike_AIAA-2011-886.pdf
[2] https://justindomke.wordpress.com/2009/02/17/automatic-differentiation-the-most-criminally-underused-tool-in-the-potential-machine-learning-toolbox/
